# Olist Data Pipeline Analytics: Minio + Spark + Iceberg
# https://iceberg.apache.org/docs/latest/
# https://hadoop.apache.org/docs/stable/hadoop-aws/
name: olist-modern-analytics-stack

services:
  # 1. Minio (S3 Compatible Storage) - if hardcore switch to Ceph or S3
  minio:
    # https://github.com/minio/minio
    # https://docs.min.io/enterprise/aistor-object-store/reference/aistor-server/settings/root-credentials/
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z-cpuv1
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console

  # 2. Minio Client (mc) - optional, for easier Minio management
  mc:
    # https://hub.docker.com/r/minio/mc
    # tail -f /dev/null - to keep the container running
    image: minio/mc:RELEASE.2025-08-13T08-35-41Z-cpuv1
    container_name: minio-mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until mc alias set local http://minio:9000 minioadmin minioadmin; do sleep 1; done;
      mc mb -p local/warehouse;
      mc mb -p local/raw;
      mc mb -p local/staging;
      tail -f /dev/null
      "
  
  # 3. Apache Spark - version affected by Iceberg compatibility
  # https://iceberg.apache.org/releases/  - showed the latest jar
  # https://iceberg.apache.org/spark-quickstart/#docker-compose  - show a docker-compose example
  # https://spark.apache.org/downloads.html  - show hadoop version 
  # https://central.sonatype.com/artifact/org.apache.hadoop/hadoop-aws/  - show 3.4.2
  spark:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: spark
    depends_on:
      - minio
    ports:
      - 8888:8888   # Jupyter
      - 8080:8080   # Spark UI
      - 10000:10000 # Thrift server
      - 10001:10001 # optional additional port
    environment:
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_REGION: us-east-1
    volumes:
      - ./warehouse:/home/iceberg/warehouse
      - ./notebooks:/home/iceberg/notebooks/notebooks
    # https://iceberg.apache.org/spark-quickstart/#adding-iceberg-to-spark
    command: >
      /opt/spark/bin/spark-sql
      --packages org.apache.iceberg:iceberg-spark-runtime-4.0_2.13:1.10.1, 
      org.apache.hadoop:hadoop-aws:3.4.2


networks:
  default:
    external: true
    name: data-pipeline-net

volumes:
  minio_data: