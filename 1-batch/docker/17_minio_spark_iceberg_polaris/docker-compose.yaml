# Olist Data Pipeline Analytics: Minio + Spark + Iceberg + Polaris (1.2.0-incubating)
# https://iceberg.apache.org/docs/latest/
# https://hadoop.apache.org/docs/stable/hadoop-aws/
name: olist-modern-analytics-stack

services:
  # 1. Minio (S3 Compatible Storage) - if hardcore switch to Ceph or S3
  minio:
    # https://github.com/minio/minio
    # https://docs.min.io/enterprise/aistor-object-store/reference/aistor-server/settings/root-credentials/
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z-cpuv1
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console

  # 2. Minio Client (mc) - optional, for easier Minio management
  mc:
    # https://hub.docker.com/r/minio/mc
    # tail -f /dev/null - to keep the container running
    image: minio/mc:RELEASE.2025-08-13T08-35-41Z-cpuv1
    container_name: minio-mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for MinIO...';
      while ! mc alias set local http://minio:9000 minioadmin minioadmin; do
        echo 'MinIO not reachable yet, retrying in 2s...';
        sleep 2;
      done;

      echo 'MinIO is ready. Creating buckets...';
      mc mb --ignore-existing local/warehouse;
      mc mb --ignore-existing local/raw;
      mc mb --ignore-existing local/staging;
      
      echo 'Buckets created successfully:';
      mc ls local;
      tail -f /dev/null
      "
  
  # 3. Apache Spark - version affected by Iceberg compatibility
  # https://iceberg.apache.org/releases/  - showed the latest jar
  # https://iceberg.apache.org/spark-quickstart/#docker-compose  - show a docker-compose example
  # print(spark._jvm.org.apache.hadoop.util.VersionInfo.getVersion())  - show hadoop version 
  # https://central.sonatype.com/artifact/org.apache.hadoop/hadoop-aws/  - show 3.4.2
  spark:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: spark
    depends_on:
      - minio
      - polaris
    ports:
      - 8888:8888   # Jupyter
      - 4040:4040   # Spark UI
      - 10000:10000 # Thrift server
      - 10001:10001 # optional additional port
    environment:
      # these are added by gpt during debugging
      SPARK_LOCAL_IP: 0.0.0.0
      SPARK_UI_BIND_ADDRESS: 0.0.0.0
      SPARK_UI_PORT: 4040
      SPARK_CONF_DIR: /opt/spark/conf
      SPARK_HOME: /opt/spark
      AWS_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
    volumes:
      # - ./warehouse:/home/iceberg/warehouse (minio have persistent volume)
      - ./notebooks:/home/iceberg/notebooks
      - ./spark/conf:/opt/spark/conf
    # https://iceberg.apache.org/spark-quickstart/#adding-iceberg-to-spark

  # 4. Polaris (Iceberg REST catalog) 
  polaris:
    image: apache/polaris:1.2.0-incubating
    container_name: polaris
    ports:
      - "8181:8181" # The API we will talk to
      - "8182:8182" # Admin/Management
    environment:
      AWS_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      #JAVA_OPTS: -Daws.region=us-east-1
      AWS_ENDPOINT: http://minio:9000/
      AWS_S3_FORCE_PATH_STYLE: "true"
      # these are needed to create token
      POLARIS_BOOTSTRAP_CREDENTIALS: POLARIS,admin,password123
      POLARIS_REALM: POLARIS
      
networks:
  default:
    external: true
    name: data-pipeline-net

volumes:
  minio_data: